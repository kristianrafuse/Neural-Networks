{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EIN', 'NAME', 'APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\n",
       "       'USE_CASE', 'ORGANIZATION', 'STATUS', 'INCOME_AMT',\n",
       "       'SPECIAL_CONSIDERATIONS', 'ASK_AMT', 'IS_SUCCESSFUL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable of the model is:\\\n",
    "\"IS_SUCCESSFUL\"\n",
    "\n",
    "The features variables are:\\\n",
    "'APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\\\n",
    "'USE_CASE', 'ORGANIZATION', 'STATUS', 'INCOME_AMT',\\\n",
    "'SPECIAL_CONSIDERATIONS', 'ASK_AMT'\n",
    "\n",
    "\n",
    "The goal is to create a binary classification model that can predict if an Alphabet Soup-funded organization will be successful based on the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "# After conferring with a classmate, I left 'NAME' in place. This actually seems to have a significant affect on model accuracy.\n",
    "application_df.drop(['EIN'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                      19568\n",
      "APPLICATION_TYPE             17\n",
      "AFFILIATION                   6\n",
      "CLASSIFICATION               71\n",
      "USE_CASE                      5\n",
      "ORGANIZATION                  4\n",
      "STATUS                        2\n",
      "INCOME_AMT                    9\n",
      "SPECIAL_CONSIDERATIONS        2\n",
      "ASK_AMT                    8747\n",
      "IS_SUCCESSFUL                 2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "nunique_column = application_df.nunique()\n",
    "\n",
    "print(nunique_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T29        2\n",
      "T15        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "\n",
    "print(application_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_cutoff_value = 250\n",
    "application_types_to_replace = application_counts[application_counts < application_cutoff_value].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C4120        1\n",
      "C8210        1\n",
      "C2561        1\n",
      "C4500        1\n",
      "C2150        1\n",
      "Name: CLASSIFICATION, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "C7000      777\n",
      "C1700      287\n",
      "C4000      194\n",
      "C5000      116\n",
      "C1270      114\n",
      "C2700      104\n",
      "C2800       95\n",
      "C7100       75\n",
      "C1300       58\n",
      "C1280       50\n",
      "C1230       36\n",
      "C1400       34\n",
      "C7200       32\n",
      "C2300       32\n",
      "C1240       30\n",
      "C8000       20\n",
      "C7120       18\n",
      "C1500       16\n",
      "C1800       15\n",
      "C6000       15\n",
      "C1250       14\n",
      "C8200       11\n",
      "C1238       10\n",
      "C1278       10\n",
      "C1235        9\n",
      "C1237        9\n",
      "C7210        7\n",
      "C2400        6\n",
      "C1720        6\n",
      "C4100        6\n",
      "C1257        5\n",
      "C1600        5\n",
      "C1260        3\n",
      "C2710        3\n",
      "C0           3\n",
      "C3200        2\n",
      "C1234        2\n",
      "C1246        2\n",
      "C1267        2\n",
      "C1256        2\n",
      "Name: CLASSIFICATION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "print(classification_counts[classification_counts > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classification_cutoff_value = 1750\n",
    "classifications_to_replace = classification_counts[classification_counts < classification_cutoff_value].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MINORITY ORGAN &amp; TISSUE TRANSPLANT &amp; EDUCATION...</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRIENDS OF ARTS COUNCIL OF GREATER DENHAM SPRI...</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISRAEL EMERGENCY ALLIANCE</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>N</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARAMCO BRATS INC</td>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NAME APPLICATION_TYPE  \\\n",
       "0                       BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1             AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2                 ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3                     SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4           GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "5  MINORITY ORGAN & TISSUE TRANSPLANT & EDUCATION...               T3   \n",
       "6  FRIENDS OF ARTS COUNCIL OF GREATER DENHAM SPRI...               T3   \n",
       "7                          ISRAEL EMERGENCY ALLIANCE               T3   \n",
       "8                                   ARAMCO BRATS INC               T7   \n",
       "9         INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS               T5   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "5       Independent          C1200  Preservation         Trust       1   \n",
       "6       Independent          C1000  Preservation         Trust       1   \n",
       "7       Independent          C2000  Preservation         Trust       1   \n",
       "8       Independent          C1000    ProductDev         Trust       1   \n",
       "9  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  \n",
       "5              0                      N     5000              1  \n",
       "6  100000-499999                      N    31452              1  \n",
       "7        10M-50M                      N  7508025              1  \n",
       "8         1-9999                      N    94389              1  \n",
       "9              0                      N     5000              0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df_dummies = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df_dummies['IS_SUCCESSFUL']\n",
    "X = application_df_dummies.drop(columns='IS_SUCCESSFUL')\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 15)                294180    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 11)                176       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 294368 (1.12 MB)\n",
      "Trainable params: 294368 (1.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer. \n",
    "# The definitions below are based on the results of tuning coded below.\n",
    "# Initial manual adjustments yeilded model with 73% accuacy. Below the tuner has configured models \n",
    "# with 79% and 80% accuracy.  \n",
    "# Commented out sections are due to the tuner only selecting 2 layers.  \n",
    "\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"linear\", input_dim=input_dim))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=11, activation=\"linear\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "# nn_model.add(tf.keras.layers.Dense(units=97, activation=\"linear\"))\n",
    "\n",
    "# # Fourth hidden layer\n",
    "# nn_model.add(tf.keras.layers.Dense(units=57, activation=\"linear\"))\n",
    "\n",
    "# # Fifth hidden layer\n",
    "# nn_model.add(tf.keras.layers.Dense(units=15, activation=\"linear\"))\n",
    "\n",
    "# # Sixth hidden layer\n",
    "# nn_model.add(tf.keras.layers.Dense(units=87, activation=\"linear\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.6265 - accuracy: 0.6711\n",
      "Epoch 2/6\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.4089 - accuracy: 0.8258\n",
      "Epoch 3/6\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.1151 - accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.1026 - accuracy: 0.9600\n",
      "Epoch 5/6\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.1006 - accuracy: 0.9606\n",
      "Epoch 6/6\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.0992 - accuracy: 0.9597\n"
     ]
    }
   ],
   "source": [
    "# Train the model. Epochs above 6 seem to overfit the data, yeilding high training accuracy, \n",
    "# but resulting in poorer testing accuracy.\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.4531 - accuracy: 0.7948 - 628ms/epoch - 2ms/step\n",
      "Loss: 0.4531373083591461, Accuracy: 0.7947521805763245\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options to determine best layers/activation.\n",
    "# This will allow us to determine an accurate model. \n",
    "\n",
    "def create_model(hp):\n",
    "    \n",
    "    nn_model2 = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','linear','softmax'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model2.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=5,\n",
    "        max_value=100,\n",
    "        step=5), activation=activation, input_dim=input_dim))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        nn_model2.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=5,\n",
    "            max_value=100,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model2.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    hyperband_iterations=3,\n",
    "    project_name='tuner1_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 01m 11s]\n",
      "val_accuracy: 0.7916035056114197\n",
      "\n",
      "Best val_accuracy So Far: 0.7995335459709167\n",
      "Total elapsed time: 01h 49m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled,y_train,epochs=1,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'linear', 'first_units': 65, 'num_layers': 3, 'units_0': 95, 'units_1': 47, 'units_2': 51, 'units_3': 15, 'tuner/epochs': 4, 'tuner/initial_epoch': 2, 'tuner/bracket': 2, 'tuner/round': 1, 'tuner/trial_id': '0010'}\n"
     ]
    }
   ],
   "source": [
    "# Get top model hyperparameters and print the values\n",
    "top_hyper = tuner.get_best_hyperparameters(1)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to the above results, a tuner search set to max_epochs=50,\\\n",
    "and  hyperband_iterations=10 returned the best model below\\\n",
    "after 13 hours of processing: \n",
    "\n",
    "* activation: 'linear'\n",
    "* first_units: 15\n",
    "* num_layers: 2\n",
    "* units_0: 11\n",
    "* units_1: 97\n",
    "* units_2: 57\n",
    "* units_3: 15\n",
    "* units_4: 87\n",
    "* tuner/epochs: 6\n",
    "* tuner/initial_epoch: 2\n",
    "* tuner/bracket: 32\n",
    "* tuner/round: 1\n",
    "* tuner/trial_id: '0383'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.4603 - accuracy: 0.7995 - 912ms/epoch - 3ms/step\n",
      "Loss: 0.4603234529495239, Accuracy: 0.7995335459709167\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the top models against the test dataset\n",
    "top_model = tuner.get_best_models(1)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results for the model tuning with max_epochs=50 and hyperband_iterations=10:\n",
    "```\n",
    "268/268 - 1s - loss: 0.4470 - accuracy: 0.8003 - 673ms/epoch - 3ms/step\n",
    "Loss: 0.44697320461273193, Accuracy: 0.8003498315811157\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the model has exceeded the target accuracy, I am going to attempt another tuner, \\\n",
    "limiting the values based on the results of the first iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting a second tuner, limiting parameters to those close to the initial tuner's values. \n",
    "\n",
    "def create_model2(hp):\n",
    "    \n",
    "    nn_model3 = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['linear'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model3.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=100,\n",
    "        step=5), activation=activation, input_dim=input_dim))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 2)):\n",
    "        nn_model3.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=100,\n",
    "            step=5),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model3.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner2 = kt.Hyperband(\n",
    "    create_model2,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    hyperband_iterations=5,\n",
    "    project_name='tuner2_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150 Complete [00h 02m 22s]\n",
      "val_accuracy: 0.7970845699310303\n",
      "\n",
      "Best val_accuracy So Far: 0.7995335459709167\n",
      "Total elapsed time: 02h 55m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner2.search(X_train_scaled,y_train,epochs=10,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'linear', 'first_units': 36, 'num_layers': 1, 'units_0': 26, 'units_1': 76, 'tuner/epochs': 4, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "top_hyper2 = tuner2.get_best_hyperparameters(1)\n",
    "for param in top_hyper2:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.4457 - accuracy: 0.7995 - 705ms/epoch - 3ms/step\n",
      "Loss: 0.4457036256790161, Accuracy: 0.7995335459709167\n"
     ]
    }
   ],
   "source": [
    "top_model2 = tuner2.get_best_models(1)\n",
    "for model in top_model2:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krist\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "top_model2[0].save(\"top_model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second tuning attempt results: \n",
    "\n",
    "```\n",
    "Best val_accuracy So Far: 0.7995335459709167\n",
    "Total elapsed time: 01h 39m 27s\n",
    "\n",
    "Search: Running Trial #90\n",
    "\n",
    "Value             |Best Value So Far |Hyperparameter\n",
    "linear            |linear            |activation\n",
    "96                |36                |first_units\n",
    "1                 |1                 |num_layers\n",
    "61                |26                |units_0\n",
    "21                |76                |units_1\n",
    "10                |4                 |tuner/epochs\n",
    "0                 |0                 |tuner/initial_epoch\n",
    "0                 |1                 |tuner/bracket\n",
    "0                 |0                 |tuner/round\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORT\n",
    "\n",
    "The purpose of this analysis is to use the provided dataset to create a binary classifier that can predict whether applicants will be successful if funded by Alphabet Soup. I am working with a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the year, which has been provided by From Alphabet Soup’s business team.\n",
    "\n",
    "The first step in my analysis was data preprocessing. In this step, I identified the target variable of my model, from the \"IS_SUCCESSFUL\" column in the dataset. This column was binary, and determined whether the money applicants recieved was used effectively.\n",
    "\n",
    "The remainder of the dataset constitued the features of our model:\n",
    "\n",
    "* NAME — Identification column\n",
    "* APPLICATION_TYPE — Alphabet Soup application type\n",
    "* AFFILIATION — Affiliated sector of industry\n",
    "* CLASSIFICATION — Government organization classification\n",
    "* USE_CASE — Use case for funding\n",
    "* ORGANIZATION — Organization type\n",
    "* STATUS — Active status\n",
    "* INCOME_AMT — Income classification\n",
    "* SPECIAL_CONSIDERATIONS — Special considerations for application\n",
    "* ASK_AMT — Funding amount requested\n",
    "\n",
    "I removed \"EIN\" from our analysis, but kept the identifier column, 'NAME'. Initial testing suggests that NAME actually positively affects accuracy by as much as 7%. \n",
    "\n",
    "I decided to keep the data as complete as possible to avoid any bias in my assumptions regarding the importance of my features. The downfall from this approach is that the dataset remains large, with lots of features, thus taking additional computing power. \n",
    "\n",
    "### Summary\n",
    "\n",
    "I initialized a Keras Sequential model for evaluating the dataset, and began experimenting with a variety of configurations manually. I expected that our model would preform best with initial rectilinear, softmax or linear activation functions and an sigmoid output layer. Employing a sigmoid function as your output layer yeild improved accuracy when the target variable is binary. Given the type of data, it did not seem approprite to employ other activations better suited to non-linear data. These assumptions seem to be merited given the results below. After various iterations, and manually changing these values, I was acheiving a prediction of approximately 73%. After including 'NAME' in the analysis, I was able to manually acheive an accuracy of 75%. However, I was keen to see the accuracy improved, so I initialized a keras tuner to evaluate a wide range of neurons, layers, and activation functions. After 13 hours of processing this is the current best model with an accuracy of 80.03%: \n",
    "\n",
    "* activation: 'linear'\n",
    "* first_units: 15\n",
    "* num_layers: 2\n",
    "* units_0: 11\n",
    "* units_1: 97\n",
    "* units_2: 57\n",
    "* units_3: 15\n",
    "* units_4: 87\n",
    "* tuner/epochs: 6\n",
    "* tuner/initial_epoch: 2\n",
    "* tuner/bracket: 3\n",
    "* tuner/round: 1\n",
    "* tuner/trial_id: '0383'\n",
    "\n",
    "With this model, I have exceeded the target accuracy of 75% by 5%.\n",
    "\n",
    "Due to some impatience on my part, I interrupted the model tuning after 13 hours and cooked an egg on my motherboard. Additional time spent allowing the tuner to fully complete may yet yeild a model with better performance. It is my recommendation that the first tuner with 'max_epochs=50' and 'hyperband_iterations=10' be initialized again and run to completion.\n",
    "\n",
    "The limitations of this approach is that the tuner seems not to blend different types of activations, or did not run long enough to offer combinations of activations for our layers. Additional manual manipluation of the 'best-model' may also provide increased performance beyond 80% accuracy. For example, all the layers in our 'best-model' are linear, so tweaking them, or adding additional softmax or relu layers may increase performance. Manual tweaking has yet to achieve results greater than 80%. \n",
    "\n",
    "An attempt was made to find a better model within the parameters suggested by the first tuner, but has yet to yeild better results. The best results thus far for this second tuner has been 79.95%, acheiving results quite close to the performance of the initial tuner.\n",
    "\n",
    "Lastly, a combined approach using an initial PCA to determine the most important components, may well lead to improvement in computational time. By determining the most impactful principal components, the dataset and features could be reduced. It is my recommendation that a PCA analysis be completed prior to preprocessing, giving a measure of the most important features to be used in a subsequent binary classifier. However, initial attempts at manual manipulation of the dataset by reducing features has not yeilded any improvment in model accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
